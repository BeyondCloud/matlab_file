{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 512)\n",
      "restore model\n",
      "INFO:tensorflow:Restoring parameters from ./model/vowel_transfer.ckpt\n",
      "0 Train accuracy: 17.9576878944 Valid accuracy: 1.2097120841\n",
      "1 Train accuracy: 18.484134888 Valid accuracy: 1.21816888793\n",
      "2 Train accuracy: 17.7636292853 Valid accuracy: 1.16872286964\n",
      "3 Train accuracy: 17.5978577317 Valid accuracy: 1.18114963442\n",
      "4 Train accuracy: 17.7540071199 Valid accuracy: 1.19127305724\n",
      "5 Train accuracy: 17.7149804897 Valid accuracy: 1.17401378747\n",
      "6 Train accuracy: 17.7152471665 Valid accuracy: 1.17119218228\n",
      "7 Train accuracy: 17.7388286337 Valid accuracy: 1.16446805828\n",
      "8 Train accuracy: 17.8521551215 Valid accuracy: 1.16283751149\n",
      "9 Train accuracy: 18.1611452352 Valid accuracy: 1.19158756888\n",
      "10 Train accuracy: 17.5655967705 Valid accuracy: 1.151804133\n",
      "11 Train accuracy: 18.1283091856 Valid accuracy: 1.18819859246\n",
      "12 Train accuracy: 18.1375567389 Valid accuracy: 1.20357754889\n",
      "13 Train accuracy: 17.9074340628 Valid accuracy: 1.1770505771\n",
      "14 Train accuracy: 18.2283194213 Valid accuracy: 1.18836479541\n",
      "15 Train accuracy: 18.0663755832 Valid accuracy: 1.21535644782\n",
      "16 Train accuracy: 17.6919057165 Valid accuracy: 1.18133919509\n",
      "17 Train accuracy: 17.9908036778 Valid accuracy: 1.18953274801\n",
      "18 Train accuracy: 17.7645295806 Valid accuracy: 1.18842573955\n",
      "19 Train accuracy: 18.1187647426 Valid accuracy: 1.20222330455\n",
      "20 Train accuracy: 18.2345623951 Valid accuracy: 1.19416710328\n",
      "21 Train accuracy: 18.1178620414 Valid accuracy: 1.1885714864\n",
      "22 Train accuracy: 17.9122561722 Valid accuracy: 1.19960529115\n",
      "23 Train accuracy: 18.0211503153 Valid accuracy: 1.20221067162\n",
      "24 Train accuracy: 17.9970321094 Valid accuracy: 1.19738777567\n",
      "25 Train accuracy: 17.8513563807 Valid accuracy: 1.16555072735\n",
      "26 Train accuracy: 17.7777035378 Valid accuracy: 1.19734876225\n",
      "27 Train accuracy: 18.0095394734 Valid accuracy: 1.20485197628\n",
      "28 Train accuracy: 18.0081673551 Valid accuracy: 1.19882451692\n",
      "29 Train accuracy: 17.9635819145 Valid accuracy: 1.17974164174\n",
      "30 Train accuracy: 17.8194465129 Valid accuracy: 1.17084652344\n",
      "31 Train accuracy: 17.7886635262 Valid accuracy: 1.1861157214\n",
      "32 Train accuracy: 17.7611130268 Valid accuracy: 1.17806715691\n",
      "33 Train accuracy: 17.6410549337 Valid accuracy: 1.18284922754\n",
      "34 Train accuracy: 17.753166177 Valid accuracy: 1.18383023524\n",
      "35 Train accuracy: 17.7633731093 Valid accuracy: 1.18418591281\n",
      "36 Train accuracy: 17.3316907689 Valid accuracy: 1.1669600777\n",
      "37 Train accuracy: 17.7847789009 Valid accuracy: 1.1850946484\n",
      "38 Train accuracy: 17.5180548573 Valid accuracy: 1.19394795178\n",
      "39 Train accuracy: 17.4508715227 Valid accuracy: 1.16928590711\n",
      "40 Train accuracy: 17.6238771094 Valid accuracy: 1.17271420513\n",
      "41 Train accuracy: 17.4329471976 Valid accuracy: 1.17387505155\n",
      "42 Train accuracy: 17.7582363799 Valid accuracy: 1.18160971034\n",
      "43 Train accuracy: 17.6122557951 Valid accuracy: 1.16867245295\n",
      "44 Train accuracy: 17.4869835705 Valid accuracy: 1.17981937298\n",
      "45 Train accuracy: 18.0948545452 Valid accuracy: 1.18969676397\n",
      "46 Train accuracy: 17.1226291143 Valid accuracy: 1.11654687407\n",
      "47 Train accuracy: 17.3756240113 Valid accuracy: 1.16468174306\n",
      "48 Train accuracy: 17.9600341974 Valid accuracy: 1.21979520274\n",
      "49 Train accuracy: 17.9705968013 Valid accuracy: 1.2154801391\n",
      "50 Train accuracy: 18.3339368521 Valid accuracy: 1.2184345963\n",
      "51 Train accuracy: 17.6823123713 Valid accuracy: 1.16061644991\n",
      "52 Train accuracy: 17.5596520814 Valid accuracy: 1.16819233994\n",
      "53 Train accuracy: 17.4591542871 Valid accuracy: 1.16202459082\n",
      "54 Train accuracy: 17.8034364291 Valid accuracy: 1.16089664366\n",
      "55 Train accuracy: 17.6968769986 Valid accuracy: 1.18312788671\n",
      "56 Train accuracy: 17.5498614393 Valid accuracy: 1.15483462848\n",
      "57 Train accuracy: 17.4577308749 Valid accuracy: 1.14701336674\n",
      "58 Train accuracy: 17.7795971418 Valid accuracy: 1.20966003582\n",
      "59 Train accuracy: 17.5219898518 Valid accuracy: 1.21068971361\n",
      "60 Train accuracy: 17.5438120643 Valid accuracy: 1.19878847827\n",
      "61 Train accuracy: 18.146544377 Valid accuracy: 1.2354700675\n",
      "62 Train accuracy: 17.5450099123 Valid accuracy: 1.17744088474\n",
      "63 Train accuracy: 17.2145116962 Valid accuracy: 1.13788943693\n",
      "64 Train accuracy: 17.5765805411 Valid accuracy: 1.16687056968\n",
      "65 Train accuracy: 18.030670751 Valid accuracy: 1.19817776727\n",
      "66 Train accuracy: 17.4762312929 Valid accuracy: 1.19583855649\n",
      "67 Train accuracy: 17.83098703 Valid accuracy: 1.1823936537\n",
      "68 Train accuracy: 17.958015591 Valid accuracy: 1.20744057437\n",
      "69 Train accuracy: 17.710638002 Valid accuracy: 1.24315518421\n",
      "70 Train accuracy: 18.0357404293 Valid accuracy: 1.18892886378\n",
      "71 Train accuracy: 17.4461059026 Valid accuracy: 1.15985402087\n",
      "72 Train accuracy: 17.6314173026 Valid accuracy: 1.18875065593\n",
      "73 Train accuracy: 17.6731909211 Valid accuracy: 1.20555822656\n",
      "74 Train accuracy: 17.6863695521 Valid accuracy: 1.18636973911\n",
      "75 Train accuracy: 17.8773710859 Valid accuracy: 1.19565943214\n",
      "76 Train accuracy: 17.9341613373 Valid accuracy: 1.2100234926\n",
      "77 Train accuracy: 18.1200049277 Valid accuracy: 1.2289480398\n",
      "78 Train accuracy: 17.9029985504 Valid accuracy: 1.15695315247\n",
      "79 Train accuracy: 17.9271032636 Valid accuracy: 1.17894476557\n",
      "80 Train accuracy: 17.7038930702 Valid accuracy: 1.16553476365\n",
      "81 Train accuracy: 17.3451353689 Valid accuracy: 1.16780480125\n",
      "82 Train accuracy: 17.4522663832 Valid accuracy: 1.14065295814\n",
      "83 Train accuracy: 17.312782601 Valid accuracy: 1.17913766712\n",
      "84 Train accuracy: 17.2548581237 Valid accuracy: 1.15682783898\n",
      "85 Train accuracy: 17.1681265432 Valid accuracy: 1.12921516111\n",
      "86 Train accuracy: 17.2019039715 Valid accuracy: 1.13499061519\n",
      "87 Train accuracy: 17.0164421298 Valid accuracy: 1.14596368677\n",
      "88 Train accuracy: 16.7831313434 Valid accuracy: 1.12057443761\n",
      "89 Train accuracy: 17.1393992005 Valid accuracy: 1.09698662093\n",
      "90 Train accuracy: 16.9956517611 Valid accuracy: 1.14298230168\n",
      "91 Train accuracy: 17.2494432653 Valid accuracy: 1.15933037975\n",
      "92 Train accuracy: 17.3331481657 Valid accuracy: 1.15000865743\n",
      "93 Train accuracy: 17.9258849228 Valid accuracy: 1.19532793957\n",
      "94 Train accuracy: 16.8754670526 Valid accuracy: 1.14197759041\n",
      "95 Train accuracy: 16.8964855099 Valid accuracy: 1.12163863862\n",
      "96 Train accuracy: 17.3804106598 Valid accuracy: 1.17208161346\n",
      "97 Train accuracy: 17.1773384513 Valid accuracy: 1.13704154033\n",
      "98 Train accuracy: 17.0089543514 Valid accuracy: 1.1710542386\n",
      "99 Train accuracy: 17.8312839423 Valid accuracy: 1.18977100928\n",
      "Test accuracy: 0.549202626602\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#Brief:\n",
    "    # 5 layer DNN ,128 neurons per layer\n",
    "    # implement:\n",
    "    #  batch input(for GPU optimize)\n",
    "    #  N-fold cross validation\n",
    "    #  print accuacy,precision,recall\n",
    "    #  Dropout\n",
    "    #  Optimize:\n",
    "    #  batch_norm,specify momentum parameter of Adamoptimizer\n",
    "#input:\n",
    "    # mnist hand writing dataset 28*28 image(0~5 only)\n",
    "    # output: 0~5 predicted number\n",
    "#Result:\n",
    "    # We found that 5 layers is unnecessary,the network can \n",
    "    # perform well (faster) with only 2 layers\n",
    "#Training process:\n",
    "    #input 0~5 hand writting image and it's labels from MNIST\n",
    "    #image will be flatten to 1x784 array \n",
    "    #we preprocess the input with batch norm and feed them into 5 layers DNN \n",
    "    #Since ELU activation func is applied ,we use He initialize can prevent gradient from vanish\n",
    "    #The softmax function will highlight the maximun output and also keep some information of other\n",
    "    #which will make backward propogation faster and also ensure no weight become starvation\n",
    "    #The dropout technic will prevent lazy neurons\n",
    "    #We analyze accuracy,precision,recall by calculating the TP FP TN FN of each label\n",
    "    #The N-fold cross validation provide us a more reliable way to analyze data\n",
    "####################\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from tensorflow.contrib.layers import fully_connected, batch_norm\n",
    "from scipy import io\n",
    "A = abs(io.loadmat('Xia_A.mat')['a_train']);\n",
    "I = abs(io.loadmat('Xia_I.mat')['i_label']);\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "# training on MNIST but only on digits 0 to 4\n",
    "X_train1 = np.transpose(A[:,0:150])\n",
    "y_train1 = np.transpose(I[:,0:150])\n",
    "\n",
    "print(X_train1.shape)\n",
    "X_valid1 = np.transpose(A[:,151:160])\n",
    "y_valid1 = np.transpose(I[:,151:160])\n",
    "\n",
    "X_test1 = np.transpose(A[:,161:170])\n",
    "y_test1 = np.transpose(A[:,161:170])\n",
    "###### Do not modify here ###### \n",
    "\n",
    "#get next batch in order\n",
    "def next_batch(batch_size,iteration, data, labels):\n",
    "    start = batch_size*iteration\n",
    "    end = batch_size*(iteration+1)\n",
    "    return data[start:end], labels[start:end]\n",
    "\n",
    "#const parameters\n",
    "n_inputs = 512  \n",
    "n_outputs = 512\n",
    "\n",
    "#adjustable parameters\n",
    "N_neurons = 256\n",
    "learning_rate = 0.01\n",
    "momentum = 0.25\n",
    "epochs = 100\n",
    "batch_size = 128  #for GPU optimize\n",
    "dropout = 0.2\n",
    "\n",
    "# Create the model\n",
    "X = tf.placeholder(tf.float64, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float64, shape=(None), name=\"y\")\n",
    "is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "#improving traning speed\n",
    "batch_norm_params = {\n",
    "    'is_training': is_training,\n",
    "    'decay': 0.9,\n",
    "    'updates_collections': None,\n",
    "    'scale': True,\n",
    "}\n",
    "\n",
    "\n",
    "#5 fully connected layer ,128 neurons per layer with dropout\n",
    "with arg_scope(\n",
    "        [fully_connected],\n",
    "        activation_fn=tf.nn.elu,\n",
    "        weights_initializer=he_init,\n",
    "        normalizer_fn=batch_norm,\n",
    "        normalizer_params=batch_norm_params):\n",
    "    W1 = fully_connected(X,N_neurons)\n",
    "    W1_D = tf.nn.dropout(W1,dropout)\n",
    "    W2 = fully_connected(W1_D,N_neurons)\n",
    "    W2_D = tf.nn.dropout(W2,dropout)\n",
    "\n",
    "    y_hat = fully_connected(W2_D, n_outputs, activation_fn=None)\n",
    "\n",
    "\n",
    "#Add softmax to output\n",
    "\n",
    "my_logits = tf.layers.dense(y_hat,n_outputs,kernel_initializer = he_init,name='logits')\n",
    "# y_proba = tf.nn.softmax(logits ,name  = 'y_proba')\n",
    "# cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=my_logits)\n",
    "# loss = tf.reduce_mean(cross_entropy, name=\"loss\")\n",
    "\n",
    "loss = tf.reduce_sum(tf.pow(y - y_hat, 2))\n",
    "#use AdamOptimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, momentum)\n",
    "training_op = optimizer.minimize(loss,name = \"training_op\")\n",
    "\n",
    "accuracy =tf.reduce_sum(tf.pow(y - y_hat, 2))/(512*batch_size)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print('restore model')\n",
    "    saver.restore(sess, \"./model/vowel_transfer.ckpt\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for iteration in range(len(X_train1)//batch_size):\n",
    "            X_batch, y_batch = next_batch(batch_size,iteration,X_train1, y_train1)\n",
    "            sess.run(training_op, feed_dict={is_training: True, X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={is_training: False, X: X_batch, y: y_batch})\n",
    "        acc_valid = accuracy.eval(feed_dict={is_training: False, X:  X_valid1, y:  y_valid1})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Valid accuracy:\", acc_valid)\n",
    "    save_path = saver.save(sess, \"./model/vowel_transfer.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={is_training: False, X:  X_test1, y:  y_test1})\n",
    "    print( \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore model\n",
      "INFO:tensorflow:Restoring parameters from ./model/vowel_transfer.ckpt\n",
      "(150, 512)\n",
      "(150, 512)\n"
     ]
    }
   ],
   "source": [
    "import copy as cp\n",
    "y_pred = []\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print('restore model')\n",
    "    saver.restore(sess, \"./model/vowel_transfer.ckpt\")\n",
    "    print(X_train1.shape)\n",
    "    \n",
    "    y_pred=y_hat.eval( feed_dict={is_training: False,X:X_train1})\n",
    "    print(y_pred.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.34952224459\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(X_train1[1][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy import io\n",
    "\n",
    "\n",
    "io.savemat('y_pred.mat',{'y_pred':y_pred});\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
